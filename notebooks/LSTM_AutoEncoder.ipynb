{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:33:40.651939Z",
     "start_time": "2021-07-06T06:33:40.644070Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:33:41.431075Z",
     "start_time": "2021-07-06T06:33:41.421338Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:34:33.162186Z",
     "start_time": "2021-07-06T06:34:33.154862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58631, 2000, 10)\n",
      "(8744, 2000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_array = np.load('/workspace/대회/npy_files/all_array_.npy')\n",
    "inf_array = np.load('/workspace/대회/npy_files/inf_array_.npy')\n",
    "print(train_array.shape)\n",
    "print(inf_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:34:43.866095Z",
     "start_time": "2021-07-06T06:34:43.853228Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE =  128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_array[:300,:,:3], batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "inf_loader = torch.utils.data.DataLoader(inf_array[:,:,:3], batch_size = BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:34:45.628157Z",
     "start_time": "2021-07-06T06:34:45.615525Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,  input_size, hidden_size_1, hidden_size_2, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size_1 = hidden_size_1 #hidden state == output_vector\n",
    "        self.hidden_size_2 = hidden_size_2 #hidden state == output_vector\n",
    "        self.num_layers = num_layers #number of layers == 몇층\n",
    "\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size_1,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, w):\n",
    "        out_1, _ = self.lstm_1(w)\n",
    "\n",
    "        return self.lstm_2(out_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:34:48.492307Z",
     "start_time": "2021-07-06T06:34:48.480269Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size_1 = hidden_size_1 #hidden state == output_vector\n",
    "        self.hidden_size_2 = hidden_size_2 #hidden state == output_vector\n",
    "        self.num_layers = num_layers #number of layers == 몇층\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(input_size=self.hidden_size_2, hidden_size=self.hidden_size_1,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "        \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.input_size,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        out_1, _ = self.lstm_1(z)\n",
    "\n",
    "        return self.lstm_2(out_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:34:53.143222Z",
     "start_time": "2021-07-06T06:34:49.365793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UsadModel_LSTM_AE(\n",
       "  (encoder): Encoder(\n",
       "    (lstm_1): LSTM(3, 32, batch_first=True)\n",
       "    (lstm_2): LSTM(32, 16, batch_first=True)\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (lstm_1): LSTM(16, 32, batch_first=True)\n",
       "    (lstm_2): LSTM(32, 3, batch_first=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UsadModel_LSTM_AE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size_1 = hidden_size_1 #hidden state == output_vector\n",
    "        self.hidden_size_2 = hidden_size_2 #hidden state == output_vector\n",
    "        self.num_layers = num_layers #number of layers == 몇층\n",
    "        \n",
    "        self.encoder = Encoder(input_size, hidden_size_1, hidden_size_2, num_layers = 1)\n",
    "        self.decoder1 = Decoder(input_size, hidden_size_1, hidden_size_2, num_layers = 1)\n",
    "        \n",
    "    def forward(self, x, n):\n",
    "        out_, _ = self.encoder(x)        \n",
    "        out_.to(device)\n",
    "        w1, _= self.decoder1(out_)\n",
    "        w1.to(device)\n",
    "        \n",
    "        mse_ = (x-w1)**2\n",
    "\n",
    "        return mse_, w1, out_\n",
    "    \n",
    "device = 'cuda'\n",
    "model_lstam_ae = UsadModel_LSTM_AE(3,32,16)\n",
    "optimizer = torch.optim.Adam(list(model_lstam_ae.encoder.parameters())+list(model_lstam_ae.decoder1.parameters()))\n",
    "model_lstam_ae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:34:57.035885Z",
     "start_time": "2021-07-06T06:34:57.024212Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, epoch, optimizer, device='cuda'):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses_train = []\n",
    "    for batch in train_loader:\n",
    "        mse_, w1, out_ = model(batch.type(torch.FloatTensor).to(device),epoch+1)\n",
    "        loss = torch.mean(mse_)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses_train.append(loss.item())\n",
    "\n",
    "    losses_train = np.mean(losses_train)\n",
    "\n",
    "\n",
    "    return losses_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:35:07.801272Z",
     "start_time": "2021-07-06T06:35:01.323518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0  train_loss_1 - 24.719334602355957\n",
      "epoch - 1  train_loss_1 - 24.66745726267497\n",
      "epoch - 2  train_loss_1 - 24.60614077250163\n",
      "epoch - 3  train_loss_1 - 24.529312133789062\n",
      "epoch - 4  train_loss_1 - 24.431960423787434\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    train_loss_ = train(model_lstam_ae, train_loader, epochs, optimizer)\n",
    "    print(f'epoch - {epoch}  train_loss_1 - {train_loss_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:35:10.827229Z",
     "start_time": "2021-07-06T06:35:10.815755Z"
    }
   },
   "outputs": [],
   "source": [
    "def testing(model, test_loader, device = 'cuda'):\n",
    "    results = np.empty([0, 3])\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            mse_, w1, out_, = model(batch.type(torch.FloatTensor).to(device),epoch+1)\n",
    "            mse_ = mse_.cpu()\n",
    "            w1 = w1.cpu()\n",
    "            out_ = out_.cpu()\n",
    "            mse_ = np.array(mse_)\n",
    "            sum_mse = mse_.sum(axis = 1)\n",
    "            results = np.concatenate([results,sum_mse])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T06:35:25.870740Z",
     "start_time": "2021-07-06T06:35:25.864422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10461.53710938, 10381.47167969, 10819.54785156],\n",
       "       [20037.90429688, 21167.50390625, 18207.08203125],\n",
       "       [10606.8046875 , 10529.0390625 , 11033.57226562],\n",
       "       ...,\n",
       "       [14048.08398438, 14981.203125  , 14004.52050781],\n",
       "       [13712.1875    , 14330.04003906, 13644.75878906],\n",
       "       [31654.55859375, 35891.390625  , 39958.26953125]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = testing(model_lstam_ae,inf_loader)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
