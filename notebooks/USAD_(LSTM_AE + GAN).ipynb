{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:19:29.783903Z",
     "start_time": "2021-07-06T05:19:14.423Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:18:48.838073Z",
     "start_time": "2021-07-06T05:18:48.828249Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:20:34.976541Z",
     "start_time": "2021-07-06T05:20:32.235423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58631, 2000, 10)\n",
      "(8744, 2000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_array = np.load('./all_array_.npy')\n",
    "print(train_array.shape)\n",
    "\n",
    "inf_array = np.load('./inf_array_.npy')\n",
    "print(inf_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loader_dataset\n",
    "* first 3000 rows _train (this is for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:07.077687Z",
     "start_time": "2021-07-06T05:25:07.067916Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE =  128\n",
    "train_loader = torch.utils.data.DataLoader(train_array[:300,:,1:], batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "inf_loader = torch.utils.data.DataLoader(inf_array[:,:,1:], batch_size = BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:08.005698Z",
     "start_time": "2021-07-06T05:25:07.993221Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,  input_size, hidden_size_1, hidden_size_2, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size_1 = hidden_size_1 #hidden state == output_vector\n",
    "        self.hidden_size_2 = hidden_size_2 #hidden state == output_vector\n",
    "        self.num_layers = num_layers #number of layers == 몇층\n",
    "\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size_1,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.hidden_size_2,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, w):\n",
    "        out_1, _ = self.lstm_1(w)\n",
    "\n",
    "        return self.lstm_2(out_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:08.384643Z",
     "start_time": "2021-07-06T05:25:08.372071Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size_1 = hidden_size_1 #hidden state == output_vector\n",
    "        self.hidden_size_2 = hidden_size_2 #hidden state == output_vector\n",
    "        self.num_layers = num_layers #number of layers == 몇층\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(input_size=self.hidden_size_2, hidden_size=self.hidden_size_1,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "        \n",
    "        self.lstm_2 = nn.LSTM(input_size=self.hidden_size_1, hidden_size=self.input_size,\n",
    "                      num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        out_1, _ = self.lstm_1(z)\n",
    "\n",
    "        return self.lstm_2(out_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:08.777485Z",
     "start_time": "2021-07-06T05:25:08.741947Z"
    }
   },
   "outputs": [],
   "source": [
    "class UsadModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size_1 = hidden_size_1 #hidden state == output_vector\n",
    "        self.hidden_size_2 = hidden_size_2 #hidden state == output_vector\n",
    "        self.num_layers = num_layers #number of layers == 몇층\n",
    "        \n",
    "        self.encoder = Encoder(input_size, hidden_size_1, hidden_size_2, num_layers = 1)\n",
    "        self.decoder1 = Decoder(input_size, hidden_size_1, hidden_size_2, num_layers = 1)\n",
    "        self.decoder2 = Decoder(input_size, hidden_size_1, hidden_size_2, num_layers = 1)\n",
    "        \n",
    "    def forward(self, x, n):\n",
    "        out_, _ = self.encoder(x)        \n",
    "        out_.to(device)\n",
    "        w1, _= self.decoder1(out_)\n",
    "        w1.to(device)\n",
    "        w2, _ = self.decoder2(out_)\n",
    "        w2.to(device)\n",
    "        self.encoder(w1)\n",
    "        w3, _ = self.decoder2(self.encoder(w1)[0])\n",
    "        w3.to(device)\n",
    "\n",
    "        loss1 = 1/n*torch.mean((x-w1)**2)+(1-1/n)*torch.mean((x-w3)**2)\n",
    "        loss2 = 1/n*torch.mean((x-w2)**2)-(1-1/n)*torch.mean((x-w3)**2)\n",
    "        \n",
    "        return loss1, loss2, out_, w2, w3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:09.136784Z",
     "start_time": "2021-07-06T05:25:09.107219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UsadModel(\n",
       "  (encoder): Encoder(\n",
       "    (lstm_1): LSTM(9, 6, batch_first=True)\n",
       "    (lstm_2): LSTM(6, 3, batch_first=True)\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (lstm_1): LSTM(3, 6, batch_first=True)\n",
       "    (lstm_2): LSTM(6, 9, batch_first=True)\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (lstm_1): LSTM(3, 6, batch_first=True)\n",
       "    (lstm_2): LSTM(6, 9, batch_first=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = UsadModel(9,6,3)\n",
    "optimizer1 = torch.optim.Adam(list(model.encoder.parameters())+list(model.decoder1.parameters()))\n",
    "optimizer2 = torch.optim.Adam(list(model.encoder.parameters())+list(model.decoder2.parameters()))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:09.843077Z",
     "start_time": "2021-07-06T05:25:09.829840Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train(model, train_loader, val_loader, epoch, optimizer1, optimizer2, device='cuda'):\n",
    "\n",
    "def train(model, train_loader, epoch, optimizer1, optimizer2, device='cuda'):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses_train = []\n",
    "    for batch in train_loader:\n",
    "        loss1, loss2, out_,w2,w3 = model(batch.type(torch.FloatTensor).to(device),epoch+1)\n",
    "        loss1.backward(retain_graph=True)\n",
    "        loss2.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        losses_train.append([loss1.item(),loss2.item()])\n",
    "\n",
    "    losses_train = np.array(losses_train)\n",
    "    train_loss_1 = np.mean(losses_train[:,0])\n",
    "    train_loss_2 = np.mean(losses_train[:,1])\n",
    "\n",
    "\n",
    "    return train_loss_1, train_loss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:28.454751Z",
     "start_time": "2021-07-06T05:25:10.661477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0  train_loss_1 - 38.925638834635414  train_loss_2 - -25.948601722717285\n",
      "epoch - 1  train_loss_1 - 38.922767639160156  train_loss_2 - -25.94760290781657\n",
      "epoch - 2  train_loss_1 - 38.920056660970054  train_loss_2 - -25.946805318196613\n",
      "epoch - 3  train_loss_1 - 38.91743405659994  train_loss_2 - -25.94622802734375\n",
      "epoch - 4  train_loss_1 - 38.914856592814125  train_loss_2 - -25.945921262105305\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "for epoch in range(epochs):\n",
    "    train_loss_1, train_loss_2 = train(model, train_loader, epochs, optimizer1, optimizer2)\n",
    "    print(f'epoch - {epoch}  train_loss_1 - {train_loss_1}  train_loss_2 - {train_loss_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:25:32.743124Z",
     "start_time": "2021-07-06T05:25:32.726593Z"
    }
   },
   "outputs": [],
   "source": [
    "def testing(model, test_loader, alpha=.5, beta=.5, device = 'cuda'):\n",
    "    results = np.empty([0, 9])\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.type(torch.FloatTensor).to(device)\n",
    "            out_, _ = model.encoder(batch)\n",
    "            w1, _ = model.decoder1(out_)\n",
    "            w2, _ = model.decoder2(model.encoder(w1)[0])\n",
    "            \n",
    "            batch = batch.cpu()\n",
    "            w1 = w1.cpu()\n",
    "            w2 = w2.cpu()\n",
    "\n",
    "            re_loss = alpha*torch.mean((batch-w1)**2, axis=1) + beta*torch.mean((batch-w2)**2, axis=1)\n",
    "            re_loss = np.array(re_loss)\n",
    "            \n",
    "            results = np.concatenate([results,re_loss])\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T05:26:01.658040Z",
     "start_time": "2021-07-06T05:26:01.648223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.22976303e+00, 5.91227913e+00, 1.52015753e+01, ...,\n",
       "        5.62714624e+00, 5.13415003e+00, 1.89419061e-01],\n",
       "       [1.08160477e+01, 9.20279980e+00, 3.22795753e+01, ...,\n",
       "        1.04262867e+01, 1.02415524e+01, 2.14587778e-01],\n",
       "       [5.30385208e+00, 6.02832317e+00, 1.53928280e+01, ...,\n",
       "        5.71127129e+00, 5.20741749e+00, 1.88655704e-01],\n",
       "       ...,\n",
       "       [7.62569666e+00, 7.11843538e+00, 2.21021156e+01, ...,\n",
       "        6.62880373e+00, 7.83982038e+00, 1.95870474e-02],\n",
       "       [7.29513550e+00, 6.93330956e+00, 2.13109665e+01, ...,\n",
       "        6.49567556e+00, 7.50043011e+00, 1.82368327e-02],\n",
       "       [1.81279297e+01, 2.12006378e+01, 4.14322205e+01, ...,\n",
       "        1.99543285e+01, 9.87639427e+00, 1.54627132e+00]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = testing(model,inf_loader)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
